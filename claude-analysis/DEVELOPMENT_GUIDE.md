# Nova Prompt Optimizer - Development Guide

*Generated by Claude on August 3, 2025*

## Development Environment Setup

### Prerequisites

**System Requirements**:
- Python 3.11+ (required for SDK)
- Node.js 18+ (required for web interface)
- Docker & Docker Compose (required for web interface)
- Git (for version control)

**AWS Requirements**:
- AWS Account with Bedrock access
- Nova model access enabled
- IAM permissions for Bedrock operations

### Quick Start

**Option 1: SDK Only Development**
```bash
# Clone repository
git clone <repository-url>
cd nova-prompt-optimizer

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install in development mode
pip install -e ".[dev]"

# Set up AWS credentials
export AWS_ACCESS_KEY_ID="your_access_key"
export AWS_SECRET_ACCESS_KEY="your_secret_key"
export AWS_REGION="us-east-1"

# Run tests
python -m unittest discover tests/
```

**Option 2: Full Stack Development**
```bash
# Clone repository
git clone <repository-url>
cd nova-prompt-optimizer

# Automated setup (recommended)
./deploy.sh --with-dev

# Manual setup
cd ui
cp .env.example .env
# Edit .env with your configuration
docker-compose up -d

# Frontend development
cd frontend
npm install
npm run dev

# Backend development
cd ../backend
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
pip install -r requirements-test.txt
uvicorn app.main:app --reload
```

## Project Structure Deep Dive

### SDK Development Structure

```
src/amzn_nova_prompt_optimizer/
├── __init__.py                 # Package initialization with logging
├── __version__.py              # Version management
├── py.typed                    # Type hints marker
├── core/                       # Core functionality
│   ├── __init__.py
│   ├── input_adapters/         # Data input handling
│   │   ├── __init__.py
│   │   ├── prompt_adapter.py   # Prompt loading and templating
│   │   ├── dataset_adapter.py  # Dataset processing
│   │   └── metric_adapter.py   # Custom evaluation metrics
│   ├── inference/              # Model inference
│   │   ├── __init__.py
│   │   ├── adapter.py          # Bedrock integration
│   │   ├── bedrock_converse.py # Converse API wrapper
│   │   └── inference_constants.py # Model configurations
│   ├── optimizers/             # Optimization algorithms
│   │   ├── __init__.py
│   │   ├── adapter.py          # Base optimizer interface
│   │   ├── nova_prompt_optimizer/ # Main optimizer
│   │   ├── nova_meta_prompter/    # Meta prompting
│   │   └── miprov2/               # MIPROv2 implementation
│   └── evaluation/             # Evaluation framework
│       └── __init__.py
└── util/                       # Utilities
    ├── __init__.py
    ├── logging_utils.py        # Logging configuration
    └── rate_limiter.py         # API rate limiting
```

### Web Interface Development Structure

```
ui/
├── frontend/                   # React TypeScript frontend
│   ├── src/
│   │   ├── components/         # Reusable UI components
│   │   │   ├── ui/            # Base components (shadcn/ui)
│   │   │   ├── forms/         # Form components
│   │   │   ├── charts/        # Data visualization
│   │   │   └── layout/        # Layout components
│   │   ├── pages/             # Route-based pages
│   │   │   ├── DatasetManagement/
│   │   │   ├── PromptWorkbench/
│   │   │   ├── OptimizationWorkflow/
│   │   │   └── Results/
│   │   ├── services/          # API integration
│   │   ├── hooks/             # Custom React hooks
│   │   ├── types/             # TypeScript definitions
│   │   ├── store/             # State management
│   │   └── lib/               # Utility functions
│   ├── public/                # Static assets
│   ├── package.json           # Dependencies and scripts
│   └── vite.config.ts         # Build configuration
├── backend/                   # FastAPI backend
│   ├── app/
│   │   ├── __init__.py
│   │   ├── main.py            # FastAPI application
│   │   ├── routers/           # API endpoints
│   │   │   ├── __init__.py
│   │   │   ├── datasets.py
│   │   │   ├── prompts.py
│   │   │   ├── optimization.py
│   │   │   ├── metrics.py
│   │   │   └── websocket.py
│   │   ├── services/          # Business logic
│   │   ├── models/            # Database models
│   │   ├── adapters/          # SDK integration
│   │   ├── core/              # Configuration
│   │   └── db/                # Database setup
│   ├── migrations/            # Alembic migrations
│   ├── tests/                 # Backend tests
│   ├── requirements.txt       # Python dependencies
│   └── alembic.ini           # Migration configuration
└── scripts/                   # Deployment scripts
```

## Development Workflows

### SDK Development Workflow

**1. Adding a New Adapter**

```python
# Step 1: Create abstract base class (if needed)
from abc import ABC, abstractmethod
from typing import Any, List

class NewAdapter(ABC):
    @abstractmethod
    def process(self, input_data: Any) -> Any:
        """Process input data according to adapter's responsibility."""
        pass

# Step 2: Implement concrete adapter
class ConcreteNewAdapter(NewAdapter):
    def __init__(self, config: Dict[str, Any]):
        self.config = config
    
    def process(self, input_data: Any) -> Any:
        # Implementation logic
        return processed_data

# Step 3: Add to __init__.py for easy imports
from .new_adapter import ConcreteNewAdapter

# Step 4: Write comprehensive tests
class TestConcreteNewAdapter(unittest.TestCase):
    def setUp(self):
        self.adapter = ConcreteNewAdapter({"param": "value"})
    
    def test_process_valid_input(self):
        result = self.adapter.process("test_input")
        self.assertEqual(result, "expected_output")
```

**2. Adding a New Optimizer**

```python
# Step 1: Inherit from base optimizer
from amzn_nova_prompt_optimizer.core.optimizers.adapter import OptimizerAdapter

class NewOptimizer(OptimizerAdapter):
    def __init__(self, prompt_adapter, inference_adapter, dataset_adapter, metric_adapter):
        super().__init__(prompt_adapter, inference_adapter, dataset_adapter, metric_adapter)
        self.algorithm_specific_config = {}
    
    def optimize(self, **kwargs) -> PromptAdapter:
        # Optimization logic
        optimized_prompt = self._run_optimization_algorithm()
        return optimized_prompt

# Step 2: Register in __init__.py
from .new_optimizer import NewOptimizer

# Step 3: Add integration tests
class TestNewOptimizer(unittest.TestCase):
    def setUp(self):
        # Set up all required adapters
        self.prompt_adapter = Mock()
        self.inference_adapter = Mock()
        self.dataset_adapter = Mock()
        self.metric_adapter = Mock()
        
        self.optimizer = NewOptimizer(
            self.prompt_adapter,
            self.inference_adapter,
            self.dataset_adapter,
            self.metric_adapter
        )
```

### Web Interface Development Workflow

**1. Adding a New Frontend Component**

```typescript
// Step 1: Create component with TypeScript
// src/components/NewComponent.tsx
import React from 'react';
import { cn } from '@/lib/utils';

interface NewComponentProps {
  data: string;
  onAction: (value: string) => void;
  className?: string;
}

export const NewComponent: React.FC<NewComponentProps> = ({
  data,
  onAction,
  className
}) => {
  return (
    <div className={cn("default-styles", className)}>
      {/* Component implementation */}
    </div>
  );
};

// Step 2: Add to component index
// src/components/index.ts
export { NewComponent } from './NewComponent';

// Step 3: Write tests
// src/components/NewComponent.test.tsx
import { render, screen, fireEvent } from '@testing-library/react';
import { NewComponent } from './NewComponent';

describe('NewComponent', () => {
  it('renders correctly', () => {
    render(<NewComponent data="test" onAction={jest.fn()} />);
    expect(screen.getByText('test')).toBeInTheDocument();
  });
});
```

**2. Adding a New API Endpoint**

```python
# Step 1: Create router
# backend/app/routers/new_feature.py
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from app.db.database import get_db
from app.services.new_feature_service import NewFeatureService

router = APIRouter(prefix="/api/new-feature", tags=["new-feature"])

@router.post("/")
async def create_new_feature(
    data: NewFeatureCreate,
    db: Session = Depends(get_db)
):
    service = NewFeatureService(db)
    return await service.create(data)

# Step 2: Create service
# backend/app/services/new_feature_service.py
class NewFeatureService:
    def __init__(self, db: Session):
        self.db = db
    
    async def create(self, data: NewFeatureCreate) -> NewFeatureResponse:
        # Business logic implementation
        pass

# Step 3: Add to main.py
from app.routers import new_feature
app.include_router(new_feature.router)

# Step 4: Write tests
# backend/tests/test_api/test_new_feature.py
def test_create_new_feature(client, db_session):
    response = client.post("/api/new-feature/", json={"data": "test"})
    assert response.status_code == 200
```

## Testing Strategy

### SDK Testing

**Unit Tests**:
```python
# tests/core/input_adapters/test_prompt_adapter.py
import unittest
from unittest.mock import Mock, patch
from amzn_nova_prompt_optimizer.core.input_adapters.prompt_adapter import TextPromptAdapter

class TestTextPromptAdapter(unittest.TestCase):
    def setUp(self):
        self.adapter = TextPromptAdapter()
    
    def test_set_user_prompt_from_content(self):
        content = "Hello {{name}}, how are you?"
        self.adapter.set_user_prompt(content=content)
        
        self.assertEqual(self.adapter.user_prompt, content)
        self.assertIn("name", self.adapter.variables)
    
    @patch('builtins.open', mock_open(read_data="System: {{instruction}}"))
    def test_set_system_prompt_from_file(self):
        self.adapter.set_system_prompt(file_path="test.txt")
        
        self.assertEqual(self.adapter.system_prompt, "System: {{instruction}}")
        self.assertIn("instruction", self.adapter.variables)
```

**Integration Tests**:
```python
# tests/core/test_integration.py
class TestOptimizationIntegration(unittest.TestCase):
    def setUp(self):
        # Set up real adapters with mock inference
        self.prompt_adapter = TextPromptAdapter()
        self.dataset_adapter = JSONDatasetAdapter({"input"}, {"output"})
        self.metric_adapter = MockMetricAdapter()
        self.inference_adapter = Mock()
    
    def test_full_optimization_workflow(self):
        # Test complete optimization pipeline
        optimizer = NovaPromptOptimizer(
            self.prompt_adapter,
            self.inference_adapter,
            self.dataset_adapter,
            self.metric_adapter
        )
        
        result = optimizer.optimize(mode="lite")
        self.assertIsInstance(result, TextPromptAdapter)
```

### Web Interface Testing

**Frontend Testing**:
```typescript
// frontend/src/components/DatasetUpload.test.tsx
import { render, screen, fireEvent, waitFor } from '@testing-library/react';
import { DatasetUpload } from './DatasetUpload';

describe('DatasetUpload', () => {
  it('handles file upload correctly', async () => {
    const mockOnUpload = jest.fn();
    render(<DatasetUpload onUpload={mockOnUpload} />);
    
    const file = new File(['test,data\n1,2'], 'test.csv', { type: 'text/csv' });
    const input = screen.getByLabelText(/upload/i);
    
    fireEvent.change(input, { target: { files: [file] } });
    
    await waitFor(() => {
      expect(mockOnUpload).toHaveBeenCalledWith(expect.objectContaining({
        name: 'test.csv',
        type: 'text/csv'
      }));
    });
  });
});
```

**Backend Testing**:
```python
# backend/tests/test_api/test_datasets.py
def test_upload_dataset(client, db_session):
    with open("test_data.csv", "rb") as f:
        response = client.post(
            "/api/datasets/upload",
            files={"file": ("test.csv", f, "text/csv")}
        )
    
    assert response.status_code == 200
    data = response.json()
    assert data["name"] == "test.csv"
    assert "id" in data
```

**End-to-End Testing**:
```typescript
// frontend/cypress/e2e/optimization-workflow.cy.ts
describe('Optimization Workflow', () => {
  it('completes full optimization process', () => {
    cy.visit('/');
    
    // Upload dataset
    cy.get('[data-testid="dataset-upload"]').selectFile('fixtures/test-dataset.csv');
    cy.get('[data-testid="process-dataset"]').click();
    
    // Create prompt
    cy.get('[data-testid="create-prompt"]').click();
    cy.get('[data-testid="prompt-editor"]').type('Classify this: {{input}}');
    cy.get('[data-testid="save-prompt"]').click();
    
    // Run optimization
    cy.get('[data-testid="start-optimization"]').click();
    cy.get('[data-testid="optimization-progress"]').should('be.visible');
    
    // Check results
    cy.get('[data-testid="optimization-complete"]', { timeout: 60000 }).should('be.visible');
    cy.get('[data-testid="results-table"]').should('contain', 'Optimized Prompt');
  });
});
```

## Code Quality Standards

### Python Code Standards

**Type Hints**:
```python
from typing import Dict, List, Optional, Union, Any
from abc import ABC, abstractmethod

class ExampleClass:
    def __init__(self, config: Dict[str, Any]) -> None:
        self.config = config
    
    def process_data(self, 
                    input_data: List[Dict[str, str]], 
                    options: Optional[Dict[str, Any]] = None) -> List[str]:
        """Process input data with optional configuration.
        
        Args:
            input_data: List of dictionaries containing input data
            options: Optional configuration parameters
            
        Returns:
            List of processed strings
            
        Raises:
            ValueError: If input_data is empty
        """
        if not input_data:
            raise ValueError("Input data cannot be empty")
        
        return [self._process_item(item, options) for item in input_data]
```

**Error Handling**:
```python
import logging
from typing import Optional

logger = logging.getLogger(__name__)

class CustomError(Exception):
    """Custom exception for specific error cases."""
    pass

def robust_function(data: str) -> Optional[str]:
    try:
        result = risky_operation(data)
        logger.info(f"Successfully processed data: {data[:50]}...")
        return result
    except ValueError as e:
        logger.warning(f"Invalid data format: {e}")
        return None
    except CustomError as e:
        logger.error(f"Custom error occurred: {e}")
        raise
    except Exception as e:
        logger.error(f"Unexpected error: {e}", exc_info=True)
        raise CustomError(f"Failed to process data: {e}") from e
```

### TypeScript Code Standards

**Component Structure**:
```typescript
import React, { useState, useCallback, useMemo } from 'react';
import { cn } from '@/lib/utils';

// Props interface
interface ComponentProps {
  data: DataType[];
  onAction: (id: string) => void;
  className?: string;
  disabled?: boolean;
}

// Component implementation
export const Component: React.FC<ComponentProps> = ({
  data,
  onAction,
  className,
  disabled = false
}) => {
  // State
  const [selectedId, setSelectedId] = useState<string | null>(null);
  
  // Memoized values
  const processedData = useMemo(() => 
    data.filter(item => item.active), [data]
  );
  
  // Callbacks
  const handleClick = useCallback((id: string) => {
    if (disabled) return;
    setSelectedId(id);
    onAction(id);
  }, [disabled, onAction]);
  
  // Render
  return (
    <div className={cn("base-styles", className)}>
      {processedData.map(item => (
        <button
          key={item.id}
          onClick={() => handleClick(item.id)}
          disabled={disabled}
          className={cn(
            "item-styles",
            selectedId === item.id && "selected-styles"
          )}
        >
          {item.name}
        </button>
      ))}
    </div>
  );
};
```

**API Service Pattern**:
```typescript
// services/api.ts
class ApiService {
  private baseUrl: string;
  
  constructor(baseUrl: string) {
    this.baseUrl = baseUrl;
  }
  
  async request<T>(
    endpoint: string, 
    options: RequestInit = {}
  ): Promise<T> {
    const url = `${this.baseUrl}${endpoint}`;
    
    try {
      const response = await fetch(url, {
        headers: {
          'Content-Type': 'application/json',
          ...options.headers,
        },
        ...options,
      });
      
      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }
      
      return await response.json();
    } catch (error) {
      console.error(`API request failed: ${url}`, error);
      throw error;
    }
  }
  
  // Specific methods
  async getDatasets(): Promise<Dataset[]> {
    return this.request<Dataset[]>('/api/datasets');
  }
  
  async createOptimization(data: OptimizationRequest): Promise<OptimizationResponse> {
    return this.request<OptimizationResponse>('/api/optimization', {
      method: 'POST',
      body: JSON.stringify(data),
    });
  }
}
```

## Performance Optimization

### SDK Performance

**Memory Management**:
```python
import gc
from typing import Iterator, List

def process_large_dataset(dataset_path: str) -> Iterator[Dict[str, Any]]:
    """Process large datasets with memory efficiency."""
    with open(dataset_path, 'r') as f:
        for line in f:
            data = json.loads(line)
            yield process_item(data)
            
            # Periodic garbage collection for very large datasets
            if random.random() < 0.001:  # 0.1% chance
                gc.collect()

def batch_process(items: List[Any], batch_size: int = 100) -> Iterator[List[Any]]:
    """Process items in batches to manage memory usage."""
    for i in range(0, len(items), batch_size):
        yield items[i:i + batch_size]
```

**Caching Strategy**:
```python
from functools import lru_cache
import hashlib
import pickle

class CachedInferenceAdapter:
    def __init__(self, base_adapter, cache_size: int = 1000):
        self.base_adapter = base_adapter
        self.cache_size = cache_size
    
    @lru_cache(maxsize=1000)
    def _cached_call(self, cache_key: str, model_id: str, system_prompt: str, 
                    messages_hash: str, config_hash: str) -> str:
        # Reconstruct parameters from hashes (simplified)
        return self.base_adapter.call_model(model_id, system_prompt, messages, config)
    
    def call_model(self, model_id: str, system_prompt: str, 
                  messages: List[Dict], config: Dict) -> str:
        # Create cache key from parameters
        cache_key = self._create_cache_key(model_id, system_prompt, messages, config)
        return self._cached_call(cache_key, model_id, system_prompt, 
                               str(hash(str(messages))), str(hash(str(config))))
```

### Web Interface Performance

**Frontend Optimization**:
```typescript
// Lazy loading for large components
const OptimizationWorkflow = React.lazy(() => import('./pages/OptimizationWorkflow'));

// Memoization for expensive calculations
const ExpensiveComponent: React.FC<Props> = ({ data, filters }) => {
  const processedData = useMemo(() => {
    return data
      .filter(item => filters.includes(item.category))
      .sort((a, b) => a.score - b.score)
      .slice(0, 100); // Limit results
  }, [data, filters]);
  
  return <DataTable data={processedData} />;
};

// Virtual scrolling for large lists
import { FixedSizeList as List } from 'react-window';

const VirtualizedList: React.FC<{ items: Item[] }> = ({ items }) => (
  <List
    height={600}
    itemCount={items.length}
    itemSize={50}
    itemData={items}
  >
    {({ index, style, data }) => (
      <div style={style}>
        <ItemComponent item={data[index]} />
      </div>
    )}
  </List>
);
```

**Backend Optimization**:
```python
# Database query optimization
from sqlalchemy import select
from sqlalchemy.orm import selectinload

async def get_optimization_runs_with_details(db: Session, limit: int = 50):
    """Optimized query with eager loading."""
    query = (
        select(OptimizationRun)
        .options(
            selectinload(OptimizationRun.dataset),
            selectinload(OptimizationRun.prompt)
        )
        .order_by(OptimizationRun.created_at.desc())
        .limit(limit)
    )
    
    result = await db.execute(query)
    return result.scalars().all()

# Background task processing
from fastapi import BackgroundTasks

@router.post("/optimization/start")
async def start_optimization(
    request: OptimizationRequest,
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db)
):
    # Create optimization run record
    run = OptimizationRun(status="queued", **request.dict())
    db.add(run)
    db.commit()
    
    # Start background processing
    background_tasks.add_task(process_optimization, run.id)
    
    return {"id": run.id, "status": "queued"}
```

## Debugging and Troubleshooting

### Common Development Issues

**1. AWS Credentials Issues**:
```bash
# Debug AWS configuration
aws sts get-caller-identity

# Check environment variables
echo $AWS_ACCESS_KEY_ID
echo $AWS_REGION

# Test Bedrock access
aws bedrock list-foundation-models --region us-east-1
```

**2. Database Migration Issues**:
```bash
# Check current migration status
cd ui/backend
alembic current

# Create new migration
alembic revision --autogenerate -m "description"

# Apply migrations
alembic upgrade head

# Rollback if needed
alembic downgrade -1
```

**3. Frontend Build Issues**:
```bash
# Clear node modules and reinstall
cd ui/frontend
rm -rf node_modules package-lock.json
npm install

# Check for TypeScript errors
npm run type-check

# Build with verbose output
npm run build -- --verbose
```

### Debugging Tools

**SDK Debugging**:
```python
import logging

# Enable debug logging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger('amzn_nova_prompt_optimizer')
logger.setLevel(logging.DEBUG)

# Add debug prints in optimization
def debug_optimization_step(step_name: str, data: Any):
    logger.debug(f"Optimization step: {step_name}")
    logger.debug(f"Data: {str(data)[:200]}...")
```

**Web Interface Debugging**:
```typescript
// Frontend debugging
const DebugComponent: React.FC = () => {
  useEffect(() => {
    console.log('Component mounted');
    return () => console.log('Component unmounted');
  }, []);
  
  const handleDebugAction = () => {
    console.group('Debug Action');
    console.log('State:', state);
    console.log('Props:', props);
    console.groupEnd();
  };
  
  return <button onClick={handleDebugAction}>Debug</button>;
};
```

```python
# Backend debugging
import logging
from fastapi import Request

logger = logging.getLogger(__name__)

@app.middleware("http")
async def debug_middleware(request: Request, call_next):
    start_time = time.time()
    
    logger.debug(f"Request: {request.method} {request.url}")
    logger.debug(f"Headers: {dict(request.headers)}")
    
    response = await call_next(request)
    
    process_time = time.time() - start_time
    logger.debug(f"Response: {response.status_code} ({process_time:.3f}s)")
    
    return response
```

This development guide provides a comprehensive foundation for contributing to and extending the Nova Prompt Optimizer project.
