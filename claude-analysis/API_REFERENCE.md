# Nova Prompt Optimizer - API Reference

*Generated by Claude on August 3, 2025*

## SDK API Reference

### Core Adapters

#### Prompt Adapter

**TextPromptAdapter**
```python
from amzn_nova_prompt_optimizer.core.input_adapters.prompt_adapter import TextPromptAdapter

class TextPromptAdapter:
    def __init__(self) -> None
    
    def set_system_prompt(self, 
                         file_path: Optional[str] = None, 
                         content: Optional[str] = None, 
                         variables: Optional[Set[str]] = None) -> None
        """Set system prompt from file or content.
        
        Args:
            file_path: Path to prompt file
            content: Direct prompt content
            variables: Expected variables in prompt
        """
    
    def set_user_prompt(self, 
                       file_path: Optional[str] = None, 
                       content: Optional[str] = None, 
                       variables: Optional[Set[str]] = None) -> None
        """Set user prompt from file or content.
        
        Args:
            file_path: Path to prompt file
            content: Direct prompt content
            variables: Expected variables in prompt
        """
    
    def adapt(self) -> Dict[str, Any]
        """Convert to standardized format for optimization pipeline."""
    
    def get_variables(self) -> Set[str]
        """Get all variables found in prompts."""
    
    def render(self, variables: Dict[str, str]) -> Dict[str, str]
        """Render prompts with variable substitution."""
```

**Usage Example**:
```python
# Create prompt adapter
prompt_adapter = TextPromptAdapter()

# Set prompts
prompt_adapter.set_system_prompt(content="You are a helpful assistant.")
prompt_adapter.set_user_prompt(content="Classify this text: {{input}}")

# Get variables
variables = prompt_adapter.get_variables()  # {'input'}

# Render with data
rendered = prompt_adapter.render({"input": "This is a test message"})
```

#### Dataset Adapter

**JSONDatasetAdapter**
```python
from amzn_nova_prompt_optimizer.core.input_adapters.dataset_adapter import JSONDatasetAdapter

class JSONDatasetAdapter:
    def __init__(self, 
                 input_columns: Set[str], 
                 output_columns: Set[str]) -> None
        """Initialize with column specifications.
        
        Args:
            input_columns: Set of input column names
            output_columns: Set of output column names
        """
    
    def adapt(self, data_source: str) -> None
        """Load and process dataset from JSONL file.
        
        Args:
            data_source: Path to JSONL file
        """
    
    def split(self, 
              test_size: float, 
              stratify: bool = False) -> Tuple[JSONDatasetAdapter, JSONDatasetAdapter]
        """Split dataset into train/test sets.
        
        Args:
            test_size: Fraction for test set (0.0-1.0)
            stratify: Whether to stratify split by output columns
            
        Returns:
            Tuple of (train_adapter, test_adapter)
        """
    
    def get_data(self) -> List[Dict[str, Any]]
        """Get processed dataset."""
    
    def get_inputs(self) -> List[Dict[str, Any]]
        """Get input columns only."""
    
    def get_outputs(self) -> List[Dict[str, Any]]
        """Get output columns only."""
```

**CSVDatasetAdapter**
```python
from amzn_nova_prompt_optimizer.core.input_adapters.dataset_adapter import CSVDatasetAdapter

class CSVDatasetAdapter:
    def __init__(self, 
                 input_columns: Set[str], 
                 output_columns: Set[str]) -> None
    
    def adapt(self, data_source: str) -> None
        """Load and process dataset from CSV file."""
    
    # Same methods as JSONDatasetAdapter
```

**Usage Example**:
```python
# Create dataset adapter
dataset_adapter = JSONDatasetAdapter(
    input_columns={"input"}, 
    output_columns={"category", "urgency"}
)

# Load dataset
dataset_adapter.adapt("data/training_data.jsonl")

# Split into train/test
train_adapter, test_adapter = dataset_adapter.split(test_size=0.2, stratify=True)

# Access data
train_data = train_adapter.get_data()
inputs = train_adapter.get_inputs()
outputs = train_adapter.get_outputs()
```

#### Metric Adapter

**Base MetricAdapter**
```python
from amzn_nova_prompt_optimizer.core.input_adapters.metric_adapter import MetricAdapter
from typing import Any, List

class MetricAdapter(ABC):
    @abstractmethod
    def apply(self, y_pred: Any, y_true: Any) -> float
        """Apply metric to single prediction/ground truth pair.
        
        Args:
            y_pred: Model prediction
            y_true: Ground truth
            
        Returns:
            Metric score (0.0-1.0 for optimizers)
        """
    
    def batch_apply(self, y_preds: List[Any], y_trues: List[Any]) -> float
        """Apply metric to batch of predictions.
        
        Args:
            y_preds: List of model predictions
            y_trues: List of ground truths
            
        Returns:
            Aggregated metric score
        """
```

**Custom Metric Example**:
```python
import re
import json

class ExactMatchMetric(MetricAdapter):
    def _parse_answer(self, text: str) -> str:
        """Extract answer from model output."""
        match = re.search(r"<answer>(.*?)</answer>", text)
        return match.group(1).lower().strip() if match else ""
    
    def apply(self, y_pred: Any, y_true: Any) -> float:
        pred_answer = self._parse_answer(str(y_pred))
        true_answer = self._parse_answer(str(y_true))
        return float(pred_answer == true_answer)
    
    def batch_apply(self, y_preds: List[Any], y_trues: List[Any]) -> float:
        scores = [self.apply(pred, true) for pred, true in zip(y_preds, y_trues)]
        return sum(scores) / len(scores)

# Usage
metric = ExactMatchMetric()
score = metric.apply(
    "The answer is <answer>positive</answer>", 
    "<answer>positive</answer>"
)  # Returns 1.0
```

#### Inference Adapter

**BedrockInferenceAdapter**
```python
from amzn_nova_prompt_optimizer.core.inference.adapter import BedrockInferenceAdapter

class BedrockInferenceAdapter:
    def __init__(self, 
                 region_name: str, 
                 rate_limit: int = 2) -> None
        """Initialize Bedrock inference adapter.
        
        Args:
            region_name: AWS region for Bedrock
            rate_limit: Maximum requests per second
        """
    
    def call_model(self, 
                   model_id: str, 
                   system_prompt: str, 
                   messages: List[Dict[str, str]], 
                   inf_config: Dict[str, Any]) -> str
        """Call Nova model via Bedrock.
        
        Args:
            model_id: Nova model identifier
            system_prompt: System prompt text
            messages: List of user/assistant message turns
            inf_config: Inference configuration (temperature, max_tokens, etc.)
            
        Returns:
            Model response text
        """
```

**Usage Example**:
```python
# Create inference adapter
inference_adapter = BedrockInferenceAdapter(
    region_name="us-east-1",
    rate_limit=5  # 5 requests per second
)

# Call model
response = inference_adapter.call_model(
    model_id="us.amazon.nova-pro-v1:0",
    system_prompt="You are a helpful assistant.",
    messages=[{"user": "What is the capital of France?"}],
    inf_config={
        "temperature": 0.7,
        "max_tokens": 1000,
        "top_p": 0.9
    }
)
```

### Optimization

#### NovaPromptOptimizer

**Main Optimizer Class**
```python
from amzn_nova_prompt_optimizer.core.optimizers import NovaPromptOptimizer

class NovaPromptOptimizer:
    def __init__(self, 
                 prompt_adapter: PromptAdapter,
                 inference_adapter: InferenceAdapter,
                 dataset_adapter: DatasetAdapter,
                 metric_adapter: MetricAdapter) -> None
        """Initialize optimizer with required adapters."""
    
    def optimize(self, 
                 mode: str = "pro",
                 custom_params: Optional[Dict[str, Any]] = None,
                 enable_json_fallback: bool = True) -> PromptAdapter
        """Run optimization process.
        
        Args:
            mode: Optimization mode ('micro', 'lite', 'pro', 'premier', 'custom')
            custom_params: Custom parameters for 'custom' mode
            enable_json_fallback: Enable JSON parsing fallback
            
        Returns:
            Optimized prompt adapter
        """
```

**Mode Configurations**:
```python
OPTIMIZATION_MODES = {
    "micro": {
        "task_model_id": "us.amazon.nova-micro-v1:0",
        "num_candidates": 10,
        "num_trials": 15,
        "max_bootstrapped_demos": 3,
        "max_labeled_demos": 0
    },
    "lite": {
        "task_model_id": "us.amazon.nova-lite-v1:0",
        "num_candidates": 15,
        "num_trials": 25,
        "max_bootstrapped_demos": 4,
        "max_labeled_demos": 0
    },
    "pro": {
        "task_model_id": "us.amazon.nova-pro-v1:0",
        "num_candidates": 20,
        "num_trials": 50,
        "max_bootstrapped_demos": 5,
        "max_labeled_demos": 0
    },
    "premier": {
        "task_model_id": "us.amazon.nova-premier-v1:0",
        "num_candidates": 25,
        "num_trials": 75,
        "max_bootstrapped_demos": 6,
        "max_labeled_demos": 0
    }
}
```

**Usage Example**:
```python
# Create optimizer
optimizer = NovaPromptOptimizer(
    prompt_adapter=prompt_adapter,
    inference_adapter=inference_adapter,
    dataset_adapter=train_dataset_adapter,
    metric_adapter=metric_adapter
)

# Run optimization
optimized_prompt = optimizer.optimize(mode="pro")

# Custom optimization
optimized_prompt = optimizer.optimize(
    mode="custom",
    custom_params={
        "task_model_id": "us.amazon.nova-pro-v1:0",
        "num_candidates": 30,
        "num_trials": 100,
        "max_bootstrapped_demos": 8,
        "max_labeled_demos": 2
    }
)
```

### Evaluation

**Evaluator Class**
```python
from amzn_nova_prompt_optimizer.core.evaluation import Evaluator

class Evaluator:
    def __init__(self, 
                 prompt_adapter: PromptAdapter,
                 dataset_adapter: DatasetAdapter,
                 metric_adapter: MetricAdapter,
                 inference_adapter: InferenceAdapter) -> None
        """Initialize evaluator with required adapters."""
    
    def aggregate_score(self, model_id: str) -> float
        """Get aggregated score across entire dataset.
        
        Args:
            model_id: Nova model identifier
            
        Returns:
            Aggregated metric score
        """
    
    def scores(self, model_id: str) -> List[float]
        """Get individual scores for each dataset item.
        
        Args:
            model_id: Nova model identifier
            
        Returns:
            List of individual scores
        """
    
    def save(self, file_path: str) -> None
        """Save evaluation results to file."""
```

**Usage Example**:
```python
# Create evaluator
evaluator = Evaluator(
    prompt_adapter=optimized_prompt,
    dataset_adapter=test_dataset_adapter,
    metric_adapter=metric_adapter,
    inference_adapter=inference_adapter
)

# Get aggregate score
score = evaluator.aggregate_score("us.amazon.nova-pro-v1:0")
print(f"Test score: {score:.3f}")

# Get individual scores
individual_scores = evaluator.scores("us.amazon.nova-pro-v1:0")

# Save results
evaluator.save("evaluation_results.jsonl")
```

## Web Interface API Reference

### REST API Endpoints

#### Dataset Management

**Upload Dataset**
```http
POST /api/datasets/upload
Content-Type: multipart/form-data

file: <dataset_file>
name: string (optional)
description: string (optional)
```

**Response**:
```json
{
  "id": "uuid",
  "name": "dataset.csv",
  "description": "Dataset description",
  "file_path": "/uploads/datasets/uuid.csv",
  "input_columns": ["input"],
  "output_columns": ["category", "urgency"],
  "row_count": 1000,
  "created_at": "2025-08-03T14:00:00Z"
}
```

**List Datasets**
```http
GET /api/datasets
```

**Response**:
```json
{
  "datasets": [
    {
      "id": "uuid",
      "name": "dataset.csv",
      "description": "Dataset description",
      "row_count": 1000,
      "created_at": "2025-08-03T14:00:00Z"
    }
  ],
  "total": 1
}
```

**Get Dataset Details**
```http
GET /api/datasets/{dataset_id}
```

**Process Dataset**
```http
POST /api/datasets/{dataset_id}/process
Content-Type: application/json

{
  "input_columns": ["input"],
  "output_columns": ["category", "urgency"],
  "test_size": 0.2,
  "stratify": true
}
```

#### Prompt Management

**Create Prompt**
```http
POST /api/prompts
Content-Type: application/json

{
  "name": "Classification Prompt",
  "description": "Prompt for text classification",
  "system_prompt": "You are a helpful assistant.",
  "user_prompt": "Classify this text: {{input}}",
  "variables": ["input"]
}
```

**Response**:
```json
{
  "id": "uuid",
  "name": "Classification Prompt",
  "description": "Prompt for text classification",
  "system_prompt": "You are a helpful assistant.",
  "user_prompt": "Classify this text: {{input}}",
  "variables": ["input"],
  "created_at": "2025-08-03T14:00:00Z"
}
```

**List Prompts**
```http
GET /api/prompts
```

**Update Prompt**
```http
PUT /api/prompts/{prompt_id}
Content-Type: application/json

{
  "name": "Updated Prompt",
  "system_prompt": "You are an expert classifier.",
  "user_prompt": "Classify this text: {{input}}\nProvide category and urgency."
}
```

#### Optimization Workflow

**Start Optimization**
```http
POST /api/optimization/start
Content-Type: application/json

{
  "dataset_id": "uuid",
  "prompt_id": "uuid",
  "metric_id": "uuid",
  "optimizer_type": "NovaPromptOptimizer",
  "mode": "pro",
  "custom_params": {
    "num_candidates": 25,
    "num_trials": 60
  }
}
```

**Response**:
```json
{
  "id": "uuid",
  "status": "queued",
  "created_at": "2025-08-03T14:00:00Z"
}
```

**Get Optimization Status**
```http
GET /api/optimization/{optimization_id}
```

**Response**:
```json
{
  "id": "uuid",
  "status": "running",
  "progress": 0.45,
  "current_step": "MIPROv2 optimization",
  "estimated_completion": "2025-08-03T14:30:00Z",
  "results": null
}
```

**List Optimization Runs**
```http
GET /api/optimization/runs?limit=50&offset=0
```

#### Custom Metrics

**Create Custom Metric**
```http
POST /api/metrics
Content-Type: application/json

{
  "name": "Exact Match",
  "description": "Exact string matching metric",
  "code": "class ExactMatchMetric(MetricAdapter):\n    def apply(self, y_pred, y_true):\n        return float(str(y_pred).strip() == str(y_true).strip())"
}
```

**Test Custom Metric**
```http
POST /api/metrics/test
Content-Type: application/json

{
  "code": "class TestMetric(MetricAdapter):\n    def apply(self, y_pred, y_true):\n        return 1.0",
  "test_cases": [
    {"y_pred": "positive", "y_true": "positive"},
    {"y_pred": "negative", "y_true": "positive"}
  ]
}
```

**Response**:
```json
{
  "valid": true,
  "test_results": [1.0, 0.0],
  "average_score": 0.5,
  "errors": []
}
```

### WebSocket API

**Optimization Progress Updates**
```javascript
// Connect to WebSocket
const ws = new WebSocket('ws://localhost:8000/ws/optimization/{optimization_id}');

// Listen for progress updates
ws.onmessage = (event) => {
  const data = JSON.parse(event.data);
  console.log('Progress update:', data);
};

// Message format
{
  "type": "progress",
  "optimization_id": "uuid",
  "progress": 0.65,
  "current_step": "Evaluating candidates",
  "details": {
    "candidates_evaluated": 13,
    "total_candidates": 20,
    "best_score": 0.87
  }
}
```

**Real-time Logs**
```javascript
// Connect to logs WebSocket
const logsWs = new WebSocket('ws://localhost:8000/ws/logs/{optimization_id}');

// Listen for log messages
logsWs.onmessage = (event) => {
  const logEntry = JSON.parse(event.data);
  console.log('Log:', logEntry);
};

// Log message format
{
  "timestamp": "2025-08-03T14:15:30Z",
  "level": "INFO",
  "message": "Starting MIPROv2 optimization",
  "details": {
    "num_candidates": 20,
    "num_trials": 50
  }
}
```

### Frontend API Integration

**TypeScript Service Classes**

```typescript
// services/DatasetService.ts
export class DatasetService {
  private baseUrl = '/api/datasets';
  
  async uploadDataset(file: File, metadata?: DatasetMetadata): Promise<Dataset> {
    const formData = new FormData();
    formData.append('file', file);
    if (metadata?.name) formData.append('name', metadata.name);
    if (metadata?.description) formData.append('description', metadata.description);
    
    const response = await fetch(`${this.baseUrl}/upload`, {
      method: 'POST',
      body: formData,
    });
    
    if (!response.ok) {
      throw new Error(`Upload failed: ${response.statusText}`);
    }
    
    return response.json();
  }
  
  async getDatasets(): Promise<Dataset[]> {
    const response = await fetch(this.baseUrl);
    const data = await response.json();
    return data.datasets;
  }
  
  async processDataset(
    datasetId: string, 
    config: DatasetProcessConfig
  ): Promise<ProcessedDataset> {
    const response = await fetch(`${this.baseUrl}/${datasetId}/process`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(config),
    });
    
    return response.json();
  }
}

// services/OptimizationService.ts
export class OptimizationService {
  private baseUrl = '/api/optimization';
  
  async startOptimization(request: OptimizationRequest): Promise<OptimizationRun> {
    const response = await fetch(`${this.baseUrl}/start`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(request),
    });
    
    return response.json();
  }
  
  async getOptimizationStatus(id: string): Promise<OptimizationRun> {
    const response = await fetch(`${this.baseUrl}/${id}`);
    return response.json();
  }
  
  // WebSocket connection for real-time updates
  connectToProgress(optimizationId: string): WebSocket {
    const ws = new WebSocket(`ws://localhost:8000/ws/optimization/${optimizationId}`);
    return ws;
  }
}
```

**React Hooks for API Integration**

```typescript
// hooks/useOptimization.ts
export const useOptimization = (optimizationId?: string) => {
  const [optimization, setOptimization] = useState<OptimizationRun | null>(null);
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  
  const startOptimization = useCallback(async (request: OptimizationRequest) => {
    setLoading(true);
    setError(null);
    
    try {
      const service = new OptimizationService();
      const result = await service.startOptimization(request);
      setOptimization(result);
      return result;
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Unknown error');
      throw err;
    } finally {
      setLoading(false);
    }
  }, []);
  
  // WebSocket connection for real-time updates
  useEffect(() => {
    if (!optimizationId) return;
    
    const service = new OptimizationService();
    const ws = service.connectToProgress(optimizationId);
    
    ws.onmessage = (event) => {
      const update = JSON.parse(event.data);
      setOptimization(prev => prev ? { ...prev, ...update } : null);
    };
    
    return () => ws.close();
  }, [optimizationId]);
  
  return {
    optimization,
    loading,
    error,
    startOptimization,
  };
};
```

## Error Handling

### SDK Error Types

```python
# Custom exceptions
class NovaPromptOptimizerError(Exception):
    """Base exception for Nova Prompt Optimizer."""
    pass

class AdapterError(NovaPromptOptimizerError):
    """Error in adapter configuration or operation."""
    pass

class OptimizationError(NovaPromptOptimizerError):
    """Error during optimization process."""
    pass

class InferenceError(NovaPromptOptimizerError):
    """Error during model inference."""
    pass

# Usage in code
try:
    optimizer = NovaPromptOptimizer(...)
    result = optimizer.optimize(mode="pro")
except OptimizationError as e:
    logger.error(f"Optimization failed: {e}")
    # Handle optimization-specific error
except InferenceError as e:
    logger.error(f"Model inference failed: {e}")
    # Handle inference-specific error
except Exception as e:
    logger.error(f"Unexpected error: {e}")
    # Handle unexpected errors
```

### Web API Error Responses

```json
{
  "error": {
    "code": "VALIDATION_ERROR",
    "message": "Invalid input data",
    "details": {
      "field": "input_columns",
      "reason": "Must be a non-empty list"
    },
    "timestamp": "2025-08-03T14:00:00Z"
  }
}
```

**Common Error Codes**:
- `VALIDATION_ERROR`: Invalid request data
- `NOT_FOUND`: Resource not found
- `UNAUTHORIZED`: Authentication required
- `FORBIDDEN`: Insufficient permissions
- `RATE_LIMITED`: Too many requests
- `INTERNAL_ERROR`: Server error
- `OPTIMIZATION_FAILED`: Optimization process failed
- `MODEL_ERROR`: Model inference error

This API reference provides comprehensive documentation for integrating with and extending the Nova Prompt Optimizer.
